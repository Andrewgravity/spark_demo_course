{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4df6277",
   "metadata": {},
   "source": [
    "import libraries(I provide all libs that I need when make this tasks, if you need some external import them here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a47a4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "039cec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import max, avg, min\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.functions import when\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b818f1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72c2f4d",
   "metadata": {},
   "source": [
    "create local SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93690102",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('FirstSparkApp.com') \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142f2acb",
   "metadata": {},
   "source": [
    "read csv with inferschema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09e3c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.options(inferSchema=True, header=True).csv(\"ds_salaries.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1c3ccf",
   "metadata": {},
   "source": [
    "read csv one more time with the same code and you will see that it almostly don't take time, because info already in SparkSession and it will not read nothing\n",
    "from this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0d89c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.options(inferSchema=True, header=True).csv(\"ds_salaries.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4646749",
   "metadata": {},
   "source": [
    "write schema of scv on screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e699d47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- work_year: integer (nullable = true)\n",
      " |-- experience_level: string (nullable = true)\n",
      " |-- employment_type: string (nullable = true)\n",
      " |-- job_title: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- salary_currency: string (nullable = true)\n",
      " |-- salary_in_usd: integer (nullable = true)\n",
      " |-- employee_residence: string (nullable = true)\n",
      " |-- remote_ratio: integer (nullable = true)\n",
      " |-- company_location: string (nullable = true)\n",
      " |-- company_size: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "52c9fbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = df.schema.json()\n",
    "with open('schema.txt', 'w') as F:  \n",
    "    json.dump(schema, F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82a2fa8",
   "metadata": {},
   "source": [
    "create schema of this scv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef8abb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"fields\":[{\"metadata\":{},\"name\":\"_c0\",\"nullable\":true,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"work_year\",\"nullable\":true,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"experience_level\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"employment_type\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"job_title\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"salary\",\"nullable\":true,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"salary_currency\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"salary_in_usd\",\"nullable\":true,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"employee_residence\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"remote_ratio\",\"nullable\":true,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"company_location\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"company_size\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a290f137",
   "metadata": {},
   "source": [
    "restart kernel without cleaning output and after restarting you need to initialize SparkSession, after initialize start execute only cells from cell with schema=\n",
    "=StructType.... \n",
    "To restart kernel click Kernel, Restart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899909ec",
   "metadata": {},
   "source": [
    "read ds_salaries with predefined schema and compare results from this cell and cell with inferSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cc40081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('schema.txt', 'r') as F:  \n",
    "    saved_schema = json.load(F)\n",
    "    \n",
    "new_schema = StructType.fromJson(json.loads(saved_schema))\n",
    "df = spark.read.options(inferSchema=True, header=True, schema=new_schema).csv(\"ds_salaries.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f78913",
   "metadata": {},
   "source": [
    "this happens because read operation is lazy(transformation), but if you use inferschema it start to be action that will create Spark Job, because Spark need to loop throw all file to check datatypes for all columns and this can harm to your code(if we compare to parquet, it will also go to check data types, but parquet provide meta information, so Spark will not go throw all file, he will just read meta information, but csv don't provide such meta information). Also header make Spark to create one more Spark Job to check first line\n",
    "to define name of columns and remember to skeep it when reading. Actual reading start when you will use first action. More about Spark Jobs you will see in next topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925c5961",
   "metadata": {},
   "source": [
    "write schema of scv on screen one more time and compare with previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3e60d88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- work_year: integer (nullable = true)\n",
      " |-- experience_level: string (nullable = true)\n",
      " |-- employment_type: string (nullable = true)\n",
      " |-- job_title: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- salary_currency: string (nullable = true)\n",
      " |-- salary_in_usd: integer (nullable = true)\n",
      " |-- employee_residence: string (nullable = true)\n",
      " |-- remote_ratio: integer (nullable = true)\n",
      " |-- company_location: string (nullable = true)\n",
      " |-- company_size: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc54467",
   "metadata": {},
   "source": [
    "now continue to work with one of the dataframes that you create"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50ba4c9",
   "metadata": {},
   "source": [
    "print data in dataframe using df.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "69ea10eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------------+---------------+--------------------+--------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|_c0|work_year|experience_level|employment_type|           job_title|  salary|salary_currency|salary_in_usd|employee_residence|remote_ratio|company_location|company_size|\n",
      "+---+---------+----------------+---------------+--------------------+--------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|  0|     2020|              MI|             FT|      Data Scientist|   70000|            EUR|        79833|                DE|           0|              DE|           L|\n",
      "|  1|     2020|              SE|             FT|Machine Learning ...|  260000|            USD|       260000|                JP|           0|              JP|           S|\n",
      "|  2|     2020|              SE|             FT|   Big Data Engineer|   85000|            GBP|       109024|                GB|          50|              GB|           M|\n",
      "|  3|     2020|              MI|             FT|Product Data Analyst|   20000|            USD|        20000|                HN|           0|              HN|           S|\n",
      "|  4|     2020|              SE|             FT|Machine Learning ...|  150000|            USD|       150000|                US|          50|              US|           L|\n",
      "|  5|     2020|              EN|             FT|        Data Analyst|   72000|            USD|        72000|                US|         100|              US|           L|\n",
      "|  6|     2020|              SE|             FT| Lead Data Scientist|  190000|            USD|       190000|                US|         100|              US|           S|\n",
      "|  7|     2020|              MI|             FT|      Data Scientist|11000000|            HUF|        35735|                HU|          50|              HU|           L|\n",
      "|  8|     2020|              MI|             FT|Business Data Ana...|  135000|            USD|       135000|                US|         100|              US|           L|\n",
      "|  9|     2020|              SE|             FT|  Lead Data Engineer|  125000|            USD|       125000|                NZ|          50|              NZ|           S|\n",
      "| 10|     2020|              EN|             FT|      Data Scientist|   45000|            EUR|        51321|                FR|           0|              FR|           S|\n",
      "| 11|     2020|              MI|             FT|      Data Scientist| 3000000|            INR|        40481|                IN|           0|              IN|           L|\n",
      "| 12|     2020|              EN|             FT|      Data Scientist|   35000|            EUR|        39916|                FR|           0|              FR|           M|\n",
      "| 13|     2020|              MI|             FT|   Lead Data Analyst|   87000|            USD|        87000|                US|         100|              US|           L|\n",
      "| 14|     2020|              MI|             FT|        Data Analyst|   85000|            USD|        85000|                US|         100|              US|           L|\n",
      "| 15|     2020|              MI|             FT|        Data Analyst|    8000|            USD|         8000|                PK|          50|              PK|           L|\n",
      "| 16|     2020|              EN|             FT|       Data Engineer| 4450000|            JPY|        41689|                JP|         100|              JP|           S|\n",
      "| 17|     2020|              SE|             FT|   Big Data Engineer|  100000|            EUR|       114047|                PL|         100|              GB|           S|\n",
      "| 18|     2020|              EN|             FT|Data Science Cons...|  423000|            INR|         5707|                IN|          50|              IN|           M|\n",
      "| 19|     2020|              MI|             FT|  Lead Data Engineer|   56000|            USD|        56000|                PT|         100|              US|           M|\n",
      "+---+---------+----------------+---------------+--------------------+--------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f1dd47",
   "metadata": {},
   "source": [
    "print data in dataframe using display(df.toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e1d5a7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>70000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>79833</td>\n",
       "      <td>DE</td>\n",
       "      <td>0</td>\n",
       "      <td>DE</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Scientist</td>\n",
       "      <td>260000</td>\n",
       "      <td>USD</td>\n",
       "      <td>260000</td>\n",
       "      <td>JP</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>85000</td>\n",
       "      <td>GBP</td>\n",
       "      <td>109024</td>\n",
       "      <td>GB</td>\n",
       "      <td>50</td>\n",
       "      <td>GB</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Product Data Analyst</td>\n",
       "      <td>20000</td>\n",
       "      <td>USD</td>\n",
       "      <td>20000</td>\n",
       "      <td>HN</td>\n",
       "      <td>0</td>\n",
       "      <td>HN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>150000</td>\n",
       "      <td>USD</td>\n",
       "      <td>150000</td>\n",
       "      <td>US</td>\n",
       "      <td>50</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>602</td>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>154000</td>\n",
       "      <td>USD</td>\n",
       "      <td>154000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>603</td>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>126000</td>\n",
       "      <td>USD</td>\n",
       "      <td>126000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>604</td>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>129000</td>\n",
       "      <td>USD</td>\n",
       "      <td>129000</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>605</td>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>150000</td>\n",
       "      <td>USD</td>\n",
       "      <td>150000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>606</td>\n",
       "      <td>2022</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>AI Scientist</td>\n",
       "      <td>200000</td>\n",
       "      <td>USD</td>\n",
       "      <td>200000</td>\n",
       "      <td>IN</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>607 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     _c0  work_year experience_level employment_type  \\\n",
       "0      0       2020               MI              FT   \n",
       "1      1       2020               SE              FT   \n",
       "2      2       2020               SE              FT   \n",
       "3      3       2020               MI              FT   \n",
       "4      4       2020               SE              FT   \n",
       "..   ...        ...              ...             ...   \n",
       "602  602       2022               SE              FT   \n",
       "603  603       2022               SE              FT   \n",
       "604  604       2022               SE              FT   \n",
       "605  605       2022               SE              FT   \n",
       "606  606       2022               MI              FT   \n",
       "\n",
       "                      job_title  salary salary_currency  salary_in_usd  \\\n",
       "0                Data Scientist   70000             EUR          79833   \n",
       "1    Machine Learning Scientist  260000             USD         260000   \n",
       "2             Big Data Engineer   85000             GBP         109024   \n",
       "3          Product Data Analyst   20000             USD          20000   \n",
       "4     Machine Learning Engineer  150000             USD         150000   \n",
       "..                          ...     ...             ...            ...   \n",
       "602               Data Engineer  154000             USD         154000   \n",
       "603               Data Engineer  126000             USD         126000   \n",
       "604                Data Analyst  129000             USD         129000   \n",
       "605                Data Analyst  150000             USD         150000   \n",
       "606                AI Scientist  200000             USD         200000   \n",
       "\n",
       "    employee_residence  remote_ratio company_location company_size  \n",
       "0                   DE             0               DE            L  \n",
       "1                   JP             0               JP            S  \n",
       "2                   GB            50               GB            M  \n",
       "3                   HN             0               HN            S  \n",
       "4                   US            50               US            L  \n",
       "..                 ...           ...              ...          ...  \n",
       "602                 US           100               US            M  \n",
       "603                 US           100               US            M  \n",
       "604                 US             0               US            M  \n",
       "605                 US           100               US            M  \n",
       "606                 IN           100               US            L  \n",
       "\n",
       "[607 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbce8b6",
   "metadata": {},
   "source": [
    "create df_job_title that consists from all job_titles without duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "94d778ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job_title = df.select('job_title').distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4577f23",
   "metadata": {},
   "source": [
    "print all rows from df_job_titles without truncating jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f5543401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|job_title                    |\n",
      "+-----------------------------+\n",
      "|3D Computer Vision Researcher|\n",
      "|Lead Data Engineer           |\n",
      "|Head of Machine Learning     |\n",
      "|Data Specialist              |\n",
      "|Data Analytics Lead          |\n",
      "|Machine Learning Scientist   |\n",
      "|Lead Data Analyst            |\n",
      "|Data Engineering Manager     |\n",
      "|Staff Data Scientist         |\n",
      "|ETL Developer                |\n",
      "+-----------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_job_title.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369b29c7",
   "metadata": {},
   "source": [
    "create  df_analytic that will consists from max, avg, min USD salaries for all job_titles using groupBy. name of fields is avg_salary, min_salary, max_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a0b9b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analytic = df.groupBy(\"job_title\").agg(max(\"salary\").alias(\"max_salary\"), \\\n",
    "                                    min(\"salary\").alias(\"min_salary\"), \\\n",
    "                                    avg(\"salary\").alias(\"avg_salary\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6722790",
   "metadata": {},
   "source": [
    "print all rows from df_analytic without trancating jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "10379fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+----------+----------+------------------+\n",
      "|job_title                               |max_salary|min_salary|avg_salary        |\n",
      "+----------------------------------------+----------+----------+------------------+\n",
      "|3D Computer Vision Researcher           |400000    |400000    |400000.0          |\n",
      "|Lead Data Engineer                      |276000    |56000     |140333.33333333334|\n",
      "|Head of Machine Learning                |6000000   |6000000   |6000000.0         |\n",
      "|Data Specialist                         |165000    |165000    |165000.0          |\n",
      "|Data Analytics Lead                     |405000    |405000    |405000.0          |\n",
      "|Machine Learning Scientist              |260000    |12000     |158412.5          |\n",
      "|Lead Data Analyst                       |1450000   |87000     |569000.0          |\n",
      "|Data Engineering Manager                |174000    |51999     |119799.8          |\n",
      "|Staff Data Scientist                    |105000    |105000    |105000.0          |\n",
      "|ETL Developer                           |50000     |50000     |50000.0           |\n",
      "|Director of Data Engineering            |200000    |82500     |141250.0          |\n",
      "|Product Data Analyst                    |450000    |20000     |235000.0          |\n",
      "|Principal Data Scientist                |416000    |130000    |206714.2857142857 |\n",
      "|AI Scientist                            |1335000   |12000     |290571.4285714286 |\n",
      "|Director of Data Science                |325000    |110000    |193285.7142857143 |\n",
      "|Machine Learning Engineer               |4900000   |20000     |272717.8780487805 |\n",
      "|Lead Data Scientist                     |3000000   |115000    |1101666.6666666667|\n",
      "|Machine Learning Infrastructure Engineer|195000    |44000     |97333.33333333333 |\n",
      "|Data Science Engineer                   |159500    |34000     |84500.0           |\n",
      "|Machine Learning Manager                |157000    |157000    |157000.0          |\n",
      "+----------------------------------------+----------+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_analytic.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db71a0c",
   "metadata": {},
   "source": [
    "now you need to add in df_analytic column row_id, that will show order of all job_titles depending on avg salary. they should be descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "82414314",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_analytic = df_analytic.sort(df_analytic.avg_salary.desc()).withColumn(\"index\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4d46af",
   "metadata": {},
   "source": [
    "print all data from df_analytic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ad0c720e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+----------+----------+------------------+-----+\n",
      "|job_title                    |max_salary|min_salary|avg_salary        |index|\n",
      "+-----------------------------+----------+----------+------------------+-----+\n",
      "|Head of Machine Learning     |6000000   |6000000   |6000000.0         |0    |\n",
      "|ML Engineer                  |8500000   |14000     |2676666.6666666665|1    |\n",
      "|BI Data Analyst              |11000000  |9272      |1902045.3333333333|2    |\n",
      "|Lead Data Scientist          |3000000   |115000    |1101666.6666666667|3    |\n",
      "|Data Science Manager         |7000000   |137141    |1062598.5833333333|4    |\n",
      "|Lead Data Analyst            |1450000   |87000     |569000.0          |5    |\n",
      "|Data Scientist               |30400000  |4000      |508347.2027972028 |6    |\n",
      "|Big Data Engineer            |1672000   |18000     |455000.0          |7    |\n",
      "|Data Analytics Lead          |405000    |405000    |405000.0          |8    |\n",
      "|3D Computer Vision Researcher|400000    |400000    |400000.0          |9    |\n",
      "|Business Data Analyst        |1400000   |50000     |355000.0          |10   |\n",
      "|Principal Data Engineer      |600000    |185000    |328333.3333333333 |11   |\n",
      "|AI Scientist                 |1335000   |12000     |290571.4285714286 |12   |\n",
      "|Financial Data Analyst       |450000    |100000    |275000.0          |13   |\n",
      "|Machine Learning Engineer    |4900000   |20000     |272717.8780487805 |14   |\n",
      "|NLP Engineer                 |240000    |240000    |240000.0          |15   |\n",
      "|Product Data Analyst         |450000    |20000     |235000.0          |16   |\n",
      "|Principal Data Scientist     |416000    |130000    |206714.2857142857 |17   |\n",
      "|Director of Data Science     |325000    |110000    |193285.7142857143 |18   |\n",
      "|Data Engineer                |4450000   |4000      |179210.55303030304|19   |\n",
      "+-----------------------------+----------+----------+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new_analytic.show(20,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7e9bed",
   "metadata": {},
   "source": [
    "it isn't beautifull, so we need to put now row_id on first place in df_analytic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e82d26e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_analytic = df_new_analytic.select(\"index\", \"job_title\", \"max_salary\", \"min_salary\", \"avg_salary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dadae23",
   "metadata": {},
   "source": [
    "print df_analytic now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c80974f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------------------+----------+----------+------------------+\n",
      "|index|job_title                    |max_salary|min_salary|avg_salary        |\n",
      "+-----+-----------------------------+----------+----------+------------------+\n",
      "|0    |Head of Machine Learning     |6000000   |6000000   |6000000.0         |\n",
      "|1    |ML Engineer                  |8500000   |14000     |2676666.6666666665|\n",
      "|2    |BI Data Analyst              |11000000  |9272      |1902045.3333333333|\n",
      "|3    |Lead Data Scientist          |3000000   |115000    |1101666.6666666667|\n",
      "|4    |Data Science Manager         |7000000   |137141    |1062598.5833333333|\n",
      "|5    |Lead Data Analyst            |1450000   |87000     |569000.0          |\n",
      "|6    |Data Scientist               |30400000  |4000      |508347.2027972028 |\n",
      "|7    |Big Data Engineer            |1672000   |18000     |455000.0          |\n",
      "|8    |Data Analytics Lead          |405000    |405000    |405000.0          |\n",
      "|9    |3D Computer Vision Researcher|400000    |400000    |400000.0          |\n",
      "|10   |Business Data Analyst        |1400000   |50000     |355000.0          |\n",
      "|11   |Principal Data Engineer      |600000    |185000    |328333.3333333333 |\n",
      "|12   |AI Scientist                 |1335000   |12000     |290571.4285714286 |\n",
      "|13   |Financial Data Analyst       |450000    |100000    |275000.0          |\n",
      "|14   |Machine Learning Engineer    |4900000   |20000     |272717.8780487805 |\n",
      "|15   |NLP Engineer                 |240000    |240000    |240000.0          |\n",
      "|16   |Product Data Analyst         |450000    |20000     |235000.0          |\n",
      "|17   |Principal Data Scientist     |416000    |130000    |206714.2857142857 |\n",
      "|18   |Director of Data Science     |325000    |110000    |193285.7142857143 |\n",
      "|19   |Data Engineer                |4450000   |4000      |179210.55303030304|\n",
      "+-----+-----------------------------+----------+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new_analytic.show(20,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c82a0f9",
   "metadata": {},
   "source": [
    "here you need to create df_exp_lvl with the biggest usd_salary(biggest_salary) for each experience_level(you need to save all fields like in entire dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "994dae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp_lvl = df.where(\"salary_currency == 'USD'\").groupBy(\"experience_level\").agg(max(\"salary\").alias(\"max\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cf510125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience_level</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EX</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MI</td>\n",
       "      <td>450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EN</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SE</td>\n",
       "      <td>412000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experience_level     max\n",
       "0               EX  600000\n",
       "1               MI  450000\n",
       "2               EN  250000\n",
       "3               SE  412000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_exp_lvl.toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8545b684",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp_lvl = df.join(df_exp_lvl, \"experience_level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bf17e075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|max   |count|\n",
      "+------+-----+\n",
      "|600000|26   |\n",
      "|450000|213  |\n",
      "|412000|280  |\n",
      "|250000|88   |\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_exp_lvl.groupBy(\"max\").count().orderBy(col(\"max\").desc()).show(20,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19794ca5",
   "metadata": {},
   "source": [
    "print here df_exp_lvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e14a6273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience_level</th>\n",
       "      <th>_c0</th>\n",
       "      <th>work_year</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MI</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>70000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>79833</td>\n",
       "      <td>DE</td>\n",
       "      <td>0</td>\n",
       "      <td>DE</td>\n",
       "      <td>L</td>\n",
       "      <td>450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SE</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Scientist</td>\n",
       "      <td>260000</td>\n",
       "      <td>USD</td>\n",
       "      <td>260000</td>\n",
       "      <td>JP</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "      <td>S</td>\n",
       "      <td>412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SE</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>FT</td>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>85000</td>\n",
       "      <td>GBP</td>\n",
       "      <td>109024</td>\n",
       "      <td>GB</td>\n",
       "      <td>50</td>\n",
       "      <td>GB</td>\n",
       "      <td>M</td>\n",
       "      <td>412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MI</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>FT</td>\n",
       "      <td>Product Data Analyst</td>\n",
       "      <td>20000</td>\n",
       "      <td>USD</td>\n",
       "      <td>20000</td>\n",
       "      <td>HN</td>\n",
       "      <td>0</td>\n",
       "      <td>HN</td>\n",
       "      <td>S</td>\n",
       "      <td>450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SE</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>150000</td>\n",
       "      <td>USD</td>\n",
       "      <td>150000</td>\n",
       "      <td>US</td>\n",
       "      <td>50</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "      <td>412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>SE</td>\n",
       "      <td>602</td>\n",
       "      <td>2022</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>154000</td>\n",
       "      <td>USD</td>\n",
       "      <td>154000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "      <td>412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>SE</td>\n",
       "      <td>603</td>\n",
       "      <td>2022</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>126000</td>\n",
       "      <td>USD</td>\n",
       "      <td>126000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "      <td>412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>SE</td>\n",
       "      <td>604</td>\n",
       "      <td>2022</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>129000</td>\n",
       "      <td>USD</td>\n",
       "      <td>129000</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "      <td>412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>SE</td>\n",
       "      <td>605</td>\n",
       "      <td>2022</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>150000</td>\n",
       "      <td>USD</td>\n",
       "      <td>150000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "      <td>412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>MI</td>\n",
       "      <td>606</td>\n",
       "      <td>2022</td>\n",
       "      <td>FT</td>\n",
       "      <td>AI Scientist</td>\n",
       "      <td>200000</td>\n",
       "      <td>USD</td>\n",
       "      <td>200000</td>\n",
       "      <td>IN</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "      <td>450000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>607 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    experience_level  _c0  work_year employment_type  \\\n",
       "0                 MI    0       2020              FT   \n",
       "1                 SE    1       2020              FT   \n",
       "2                 SE    2       2020              FT   \n",
       "3                 MI    3       2020              FT   \n",
       "4                 SE    4       2020              FT   \n",
       "..               ...  ...        ...             ...   \n",
       "602               SE  602       2022              FT   \n",
       "603               SE  603       2022              FT   \n",
       "604               SE  604       2022              FT   \n",
       "605               SE  605       2022              FT   \n",
       "606               MI  606       2022              FT   \n",
       "\n",
       "                      job_title  salary salary_currency  salary_in_usd  \\\n",
       "0                Data Scientist   70000             EUR          79833   \n",
       "1    Machine Learning Scientist  260000             USD         260000   \n",
       "2             Big Data Engineer   85000             GBP         109024   \n",
       "3          Product Data Analyst   20000             USD          20000   \n",
       "4     Machine Learning Engineer  150000             USD         150000   \n",
       "..                          ...     ...             ...            ...   \n",
       "602               Data Engineer  154000             USD         154000   \n",
       "603               Data Engineer  126000             USD         126000   \n",
       "604                Data Analyst  129000             USD         129000   \n",
       "605                Data Analyst  150000             USD         150000   \n",
       "606                AI Scientist  200000             USD         200000   \n",
       "\n",
       "    employee_residence  remote_ratio company_location company_size     max  \n",
       "0                   DE             0               DE            L  450000  \n",
       "1                   JP             0               JP            S  412000  \n",
       "2                   GB            50               GB            M  412000  \n",
       "3                   HN             0               HN            S  450000  \n",
       "4                   US            50               US            L  412000  \n",
       "..                 ...           ...              ...          ...     ...  \n",
       "602                 US           100               US            M  412000  \n",
       "603                 US           100               US            M  412000  \n",
       "604                 US             0               US            M  412000  \n",
       "605                 US           100               US            M  412000  \n",
       "606                 IN           100               US            L  450000  \n",
       "\n",
       "[607 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_exp_lvl.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16516dc6",
   "metadata": {},
   "source": [
    "create df_best that consists from rows where salary of guy same as biggest salary for other people in his exp_lvl and choose only columns: id, experience_level, biggest_salary, employee_residence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f22e1974",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best = df_exp_lvl.filter(\"salary == max\").select(\"_c0\", \"salary\", \"experience_level\", \"max\", \"employee_residence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08511de9",
   "metadata": {},
   "source": [
    "print df_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e493fa24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>salary</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>max</th>\n",
       "      <th>employee_residence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>450000</td>\n",
       "      <td>MI</td>\n",
       "      <td>450000</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>450000</td>\n",
       "      <td>MI</td>\n",
       "      <td>450000</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>250000</td>\n",
       "      <td>EN</td>\n",
       "      <td>250000</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>412000</td>\n",
       "      <td>SE</td>\n",
       "      <td>412000</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97</td>\n",
       "      <td>450000</td>\n",
       "      <td>MI</td>\n",
       "      <td>450000</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>252</td>\n",
       "      <td>600000</td>\n",
       "      <td>EX</td>\n",
       "      <td>600000</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _c0  salary experience_level     max employee_residence\n",
       "0   21  450000               MI  450000                 IN\n",
       "1   33  450000               MI  450000                 US\n",
       "2   37  250000               EN  250000                 US\n",
       "3   63  412000               SE  412000                 US\n",
       "4   97  450000               MI  450000                 US\n",
       "5  252  600000               EX  600000                 US"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_best.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecce0a0",
   "metadata": {},
   "source": [
    "drop duplicates if exist by experience_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "787af60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best = df_best.dropDuplicates(['experience_level'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4068dbed",
   "metadata": {},
   "source": [
    "print df_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4320957f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>salary</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>max</th>\n",
       "      <th>employee_residence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>250000</td>\n",
       "      <td>EN</td>\n",
       "      <td>250000</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>252</td>\n",
       "      <td>600000</td>\n",
       "      <td>EX</td>\n",
       "      <td>600000</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>450000</td>\n",
       "      <td>MI</td>\n",
       "      <td>450000</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>412000</td>\n",
       "      <td>SE</td>\n",
       "      <td>412000</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _c0  salary experience_level     max employee_residence\n",
       "0   37  250000               EN  250000                 US\n",
       "1  252  600000               EX  600000                 US\n",
       "2   21  450000               MI  450000                 IN\n",
       "3   63  412000               SE  412000                 US"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_best.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97284707",
   "metadata": {},
   "source": [
    "create df_new_best from df_best without id, and make the next: when exp_level = MI we want middle, when SE we want senior, else Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e8fb69e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_best = df_best.drop(col(\"_c0\")).withColumn(\"position\", when((df_best.experience_level == \"MI\"), lit(\"middle\")) \\\n",
    "                              .when((df_best.experience_level == \"SE\"), lit(\"senior\")) \\\n",
    "                              .otherwise(lit(None)) \\\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd2799e",
   "metadata": {},
   "source": [
    "print df_new_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a6925f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+------+------------------+--------+\n",
      "|salary|experience_level|   max|employee_residence|position|\n",
      "+------+----------------+------+------------------+--------+\n",
      "|250000|              EN|250000|                US|    null|\n",
      "|600000|              EX|600000|                US|    null|\n",
      "|450000|              MI|450000|                IN|  middle|\n",
      "|412000|              SE|412000|                US|  senior|\n",
      "+------+----------------+------+------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new_best.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9642263",
   "metadata": {},
   "source": [
    "write df_new_best like 1.csv and load then it to df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "10aeb96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_best.write.option(\"header\", True).csv(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cb9fef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = spark.read.csv(\"1\\part-00000-a001cac7-331c-446c-bf2b-5bba3d4b4033-c000.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1743d61b",
   "metadata": {},
   "source": [
    "print df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2f1ddb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+------+------------------+--------+\n",
      "|salary|experience_level|   max|employee_residence|position|\n",
      "+------+----------------+------+------------------+--------+\n",
      "|250000|              EN|250000|                US|    null|\n",
      "|600000|              EX|600000|                US|    null|\n",
      "|450000|              MI|450000|                IN|  middle|\n",
      "|412000|              SE|412000|                US|  senior|\n",
      "+------+----------------+------+------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533c4a59",
   "metadata": {},
   "source": [
    "filter df_final to delete experience_level where it Null, then join this table by biggest_salary(salary_in_usd) and employee_residence with entire df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "68ff571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "632d993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.options(inferSchema='True', header=True).csv(\"ds_salaries.csv\")\n",
    "final = df_final.join(df, (df_final.max == df.salary_in_usd) & (df_final.employee_residence == df.employee_residence), 'right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68836a6",
   "metadata": {},
   "source": [
    "print df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "336aad45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>max</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>position</th>\n",
       "      <th>_c0</th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>70000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>79833</td>\n",
       "      <td>DE</td>\n",
       "      <td>0</td>\n",
       "      <td>DE</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Scientist</td>\n",
       "      <td>260000</td>\n",
       "      <td>USD</td>\n",
       "      <td>260000</td>\n",
       "      <td>JP</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>85000</td>\n",
       "      <td>GBP</td>\n",
       "      <td>109024</td>\n",
       "      <td>GB</td>\n",
       "      <td>50</td>\n",
       "      <td>GB</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Product Data Analyst</td>\n",
       "      <td>20000</td>\n",
       "      <td>USD</td>\n",
       "      <td>20000</td>\n",
       "      <td>HN</td>\n",
       "      <td>0</td>\n",
       "      <td>HN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>150000</td>\n",
       "      <td>USD</td>\n",
       "      <td>150000</td>\n",
       "      <td>US</td>\n",
       "      <td>50</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>602</td>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>154000</td>\n",
       "      <td>USD</td>\n",
       "      <td>154000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>603</td>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>126000</td>\n",
       "      <td>USD</td>\n",
       "      <td>126000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>604</td>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>129000</td>\n",
       "      <td>USD</td>\n",
       "      <td>129000</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>605</td>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>150000</td>\n",
       "      <td>USD</td>\n",
       "      <td>150000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>606</td>\n",
       "      <td>2022</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>AI Scientist</td>\n",
       "      <td>200000</td>\n",
       "      <td>USD</td>\n",
       "      <td>200000</td>\n",
       "      <td>IN</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>607 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     salary experience_level   max employee_residence position  _c0  \\\n",
       "0      None             None  None               None     None    0   \n",
       "1      None             None  None               None     None    1   \n",
       "2      None             None  None               None     None    2   \n",
       "3      None             None  None               None     None    3   \n",
       "4      None             None  None               None     None    4   \n",
       "..      ...              ...   ...                ...      ...  ...   \n",
       "602    None             None  None               None     None  602   \n",
       "603    None             None  None               None     None  603   \n",
       "604    None             None  None               None     None  604   \n",
       "605    None             None  None               None     None  605   \n",
       "606    None             None  None               None     None  606   \n",
       "\n",
       "     work_year experience_level employment_type                   job_title  \\\n",
       "0         2020               MI              FT              Data Scientist   \n",
       "1         2020               SE              FT  Machine Learning Scientist   \n",
       "2         2020               SE              FT           Big Data Engineer   \n",
       "3         2020               MI              FT        Product Data Analyst   \n",
       "4         2020               SE              FT   Machine Learning Engineer   \n",
       "..         ...              ...             ...                         ...   \n",
       "602       2022               SE              FT               Data Engineer   \n",
       "603       2022               SE              FT               Data Engineer   \n",
       "604       2022               SE              FT                Data Analyst   \n",
       "605       2022               SE              FT                Data Analyst   \n",
       "606       2022               MI              FT                AI Scientist   \n",
       "\n",
       "     salary salary_currency  salary_in_usd employee_residence  remote_ratio  \\\n",
       "0     70000             EUR          79833                 DE             0   \n",
       "1    260000             USD         260000                 JP             0   \n",
       "2     85000             GBP         109024                 GB            50   \n",
       "3     20000             USD          20000                 HN             0   \n",
       "4    150000             USD         150000                 US            50   \n",
       "..      ...             ...            ...                ...           ...   \n",
       "602  154000             USD         154000                 US           100   \n",
       "603  126000             USD         126000                 US           100   \n",
       "604  129000             USD         129000                 US             0   \n",
       "605  150000             USD         150000                 US           100   \n",
       "606  200000             USD         200000                 IN           100   \n",
       "\n",
       "    company_location company_size  \n",
       "0                 DE            L  \n",
       "1                 JP            S  \n",
       "2                 GB            M  \n",
       "3                 HN            S  \n",
       "4                 US            L  \n",
       "..               ...          ...  \n",
       "602               US            M  \n",
       "603               US            M  \n",
       "604               US            M  \n",
       "605               US            M  \n",
       "606               US            L  \n",
       "\n",
       "[607 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(final.toPandas().iloc[:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473206aa",
   "metadata": {},
   "source": [
    "last task is to save in variable and then print this variable of the biggest salary_in_usd from df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ecd12840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|max(salary_in_usd)|\n",
      "+------------------+\n",
      "|            600000|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final.agg(max(\"salary_in_usd\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2fa21b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (10)\n",
      "+- == Final Plan ==\n",
      "   * BroadcastHashJoin RightOuter BuildLeft (6)\n",
      "   :- BroadcastQueryStage (4), Statistics(sizeInBytes=16.0 MiB, rowCount=2)\n",
      "   :  +- BroadcastExchange (3)\n",
      "   :     +- * Filter (2)\n",
      "   :        +- Scan csv  (1)\n",
      "   +- Scan csv  (5)\n",
      "+- == Initial Plan ==\n",
      "   BroadcastHashJoin RightOuter BuildLeft (9)\n",
      "   :- BroadcastExchange (8)\n",
      "   :  +- Filter (7)\n",
      "   :     +- Scan csv  (1)\n",
      "   +- Scan csv  (5)\n",
      "\n",
      "\n",
      "(1) Scan csv \n",
      "Output [5]: [salary#1389, experience_level#1390, max#1391, employee_residence#1392, position#1393]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [file:/C:/Андрей/spark_demo_course/1/part-00000-a001cac7-331c-446c-bf2b-5bba3d4b4033-c000.csv]\n",
      "PushedFilters: [IsNotNull(max), IsNotNull(employee_residence)]\n",
      "ReadSchema: struct<salary:string,experience_level:string,max:string,employee_residence:string,position:string>\n",
      "\n",
      "(2) Filter [codegen id : 1]\n",
      "Input [5]: [salary#1389, experience_level#1390, max#1391, employee_residence#1392, position#1393]\n",
      "Condition : ((atleastnnonnulls(5, salary#1389, experience_level#1390, max#1391, employee_residence#1392, position#1393) AND isnotnull(max#1391)) AND isnotnull(employee_residence#1392))\n",
      "\n",
      "(3) BroadcastExchange\n",
      "Input [5]: [salary#1389, experience_level#1390, max#1391, employee_residence#1392, position#1393]\n",
      "Arguments: HashedRelationBroadcastMode(List(cast(input[2, string, false] as int), input[3, string, false]),false), [plan_id=4079]\n",
      "\n",
      "(4) BroadcastQueryStage\n",
      "Output [5]: [salary#1389, experience_level#1390, max#1391, employee_residence#1392, position#1393]\n",
      "Arguments: 0\n",
      "\n",
      "(5) Scan csv \n",
      "Output [12]: [_c0#2003, work_year#2004, experience_level#2005, employment_type#2006, job_title#2007, salary#2008, salary_currency#2009, salary_in_usd#2010, employee_residence#2011, remote_ratio#2012, company_location#2013, company_size#2014]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [file:/C:/Андрей/spark_demo_course/ds_salaries.csv]\n",
      "ReadSchema: struct<_c0:int,work_year:int,experience_level:string,employment_type:string,job_title:string,salary:int,salary_currency:string,salary_in_usd:int,employee_residence:string,remote_ratio:int,company_location:string,company_size:string>\n",
      "\n",
      "(6) BroadcastHashJoin [codegen id : 2]\n",
      "Left keys [2]: [cast(max#1391 as int), employee_residence#1392]\n",
      "Right keys [2]: [salary_in_usd#2010, employee_residence#2011]\n",
      "Join condition: None\n",
      "\n",
      "(7) Filter\n",
      "Input [5]: [salary#1389, experience_level#1390, max#1391, employee_residence#1392, position#1393]\n",
      "Condition : ((atleastnnonnulls(5, salary#1389, experience_level#1390, max#1391, employee_residence#1392, position#1393) AND isnotnull(max#1391)) AND isnotnull(employee_residence#1392))\n",
      "\n",
      "(8) BroadcastExchange\n",
      "Input [5]: [salary#1389, experience_level#1390, max#1391, employee_residence#1392, position#1393]\n",
      "Arguments: HashedRelationBroadcastMode(List(cast(input[2, string, false] as int), input[3, string, false]),false), [plan_id=4070]\n",
      "\n",
      "(9) BroadcastHashJoin\n",
      "Left keys [2]: [cast(max#1391 as int), employee_residence#1392]\n",
      "Right keys [2]: [salary_in_usd#2010, employee_residence#2011]\n",
      "Join condition: None\n",
      "\n",
      "(10) AdaptiveSparkPlan\n",
      "Output [17]: [salary#1389, experience_level#1390, max#1391, employee_residence#1392, position#1393, _c0#2003, work_year#2004, experience_level#2005, employment_type#2006, job_title#2007, salary#2008, salary_currency#2009, salary_in_usd#2010, employee_residence#2011, remote_ratio#2012, company_location#2013, company_size#2014]\n",
      "Arguments: isFinalPlan=true\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final.explain('formatted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53768f9",
   "metadata": {},
   "source": [
    "It is the end of PySpark basics. In other lessons you will learn optimizations technics and how to make distributed system"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
